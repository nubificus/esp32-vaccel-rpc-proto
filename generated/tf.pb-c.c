/* Generated by the protocol buffer compiler.  DO NOT EDIT! */
/* Generated from: tf.proto */

/* Do not generate deprecated warnings for self */
#ifndef PROTOBUF_C__NO_DEPRECATED
#define PROTOBUF_C__NO_DEPRECATED
#endif

#include "tf.pb-c.h"
void   vaccel__tf__tensor__init
                     (Vaccel__Tf__Tensor         *message)
{
  static const Vaccel__Tf__Tensor init_value = VACCEL__TF__TENSOR__INIT;
  *message = init_value;
}
size_t vaccel__tf__tensor__get_packed_size
                     (const Vaccel__Tf__Tensor *message)
{
  assert(message->base.descriptor == &vaccel__tf__tensor__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__tensor__pack
                     (const Vaccel__Tf__Tensor *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__tensor__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__tensor__pack_to_buffer
                     (const Vaccel__Tf__Tensor *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__tensor__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__Tensor *
       vaccel__tf__tensor__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__Tensor *)
     protobuf_c_message_unpack (&vaccel__tf__tensor__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__tensor__free_unpacked
                     (Vaccel__Tf__Tensor *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__tensor__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   vaccel__tf__node__init
                     (Vaccel__Tf__Node         *message)
{
  static const Vaccel__Tf__Node init_value = VACCEL__TF__NODE__INIT;
  *message = init_value;
}
size_t vaccel__tf__node__get_packed_size
                     (const Vaccel__Tf__Node *message)
{
  assert(message->base.descriptor == &vaccel__tf__node__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__node__pack
                     (const Vaccel__Tf__Node *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__node__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__node__pack_to_buffer
                     (const Vaccel__Tf__Node *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__node__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__Node *
       vaccel__tf__node__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__Node *)
     protobuf_c_message_unpack (&vaccel__tf__node__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__node__free_unpacked
                     (Vaccel__Tf__Node *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__node__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   vaccel__tf__model_load_request__init
                     (Vaccel__Tf__ModelLoadRequest         *message)
{
  static const Vaccel__Tf__ModelLoadRequest init_value = VACCEL__TF__MODEL_LOAD_REQUEST__INIT;
  *message = init_value;
}
size_t vaccel__tf__model_load_request__get_packed_size
                     (const Vaccel__Tf__ModelLoadRequest *message)
{
  assert(message->base.descriptor == &vaccel__tf__model_load_request__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__model_load_request__pack
                     (const Vaccel__Tf__ModelLoadRequest *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__model_load_request__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__model_load_request__pack_to_buffer
                     (const Vaccel__Tf__ModelLoadRequest *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__model_load_request__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__ModelLoadRequest *
       vaccel__tf__model_load_request__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__ModelLoadRequest *)
     protobuf_c_message_unpack (&vaccel__tf__model_load_request__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__model_load_request__free_unpacked
                     (Vaccel__Tf__ModelLoadRequest *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__model_load_request__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   vaccel__tf__model_load_response__init
                     (Vaccel__Tf__ModelLoadResponse         *message)
{
  static const Vaccel__Tf__ModelLoadResponse init_value = VACCEL__TF__MODEL_LOAD_RESPONSE__INIT;
  *message = init_value;
}
size_t vaccel__tf__model_load_response__get_packed_size
                     (const Vaccel__Tf__ModelLoadResponse *message)
{
  assert(message->base.descriptor == &vaccel__tf__model_load_response__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__model_load_response__pack
                     (const Vaccel__Tf__ModelLoadResponse *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__model_load_response__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__model_load_response__pack_to_buffer
                     (const Vaccel__Tf__ModelLoadResponse *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__model_load_response__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__ModelLoadResponse *
       vaccel__tf__model_load_response__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__ModelLoadResponse *)
     protobuf_c_message_unpack (&vaccel__tf__model_load_response__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__model_load_response__free_unpacked
                     (Vaccel__Tf__ModelLoadResponse *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__model_load_response__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   vaccel__tf__model_unload_request__init
                     (Vaccel__Tf__ModelUnloadRequest         *message)
{
  static const Vaccel__Tf__ModelUnloadRequest init_value = VACCEL__TF__MODEL_UNLOAD_REQUEST__INIT;
  *message = init_value;
}
size_t vaccel__tf__model_unload_request__get_packed_size
                     (const Vaccel__Tf__ModelUnloadRequest *message)
{
  assert(message->base.descriptor == &vaccel__tf__model_unload_request__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__model_unload_request__pack
                     (const Vaccel__Tf__ModelUnloadRequest *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__model_unload_request__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__model_unload_request__pack_to_buffer
                     (const Vaccel__Tf__ModelUnloadRequest *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__model_unload_request__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__ModelUnloadRequest *
       vaccel__tf__model_unload_request__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__ModelUnloadRequest *)
     protobuf_c_message_unpack (&vaccel__tf__model_unload_request__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__model_unload_request__free_unpacked
                     (Vaccel__Tf__ModelUnloadRequest *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__model_unload_request__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   vaccel__tf__model_unload_response__init
                     (Vaccel__Tf__ModelUnloadResponse         *message)
{
  static const Vaccel__Tf__ModelUnloadResponse init_value = VACCEL__TF__MODEL_UNLOAD_RESPONSE__INIT;
  *message = init_value;
}
size_t vaccel__tf__model_unload_response__get_packed_size
                     (const Vaccel__Tf__ModelUnloadResponse *message)
{
  assert(message->base.descriptor == &vaccel__tf__model_unload_response__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__model_unload_response__pack
                     (const Vaccel__Tf__ModelUnloadResponse *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__model_unload_response__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__model_unload_response__pack_to_buffer
                     (const Vaccel__Tf__ModelUnloadResponse *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__model_unload_response__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__ModelUnloadResponse *
       vaccel__tf__model_unload_response__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__ModelUnloadResponse *)
     protobuf_c_message_unpack (&vaccel__tf__model_unload_response__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__model_unload_response__free_unpacked
                     (Vaccel__Tf__ModelUnloadResponse *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__model_unload_response__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   vaccel__tf__model_run_request__init
                     (Vaccel__Tf__ModelRunRequest         *message)
{
  static const Vaccel__Tf__ModelRunRequest init_value = VACCEL__TF__MODEL_RUN_REQUEST__INIT;
  *message = init_value;
}
size_t vaccel__tf__model_run_request__get_packed_size
                     (const Vaccel__Tf__ModelRunRequest *message)
{
  assert(message->base.descriptor == &vaccel__tf__model_run_request__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__model_run_request__pack
                     (const Vaccel__Tf__ModelRunRequest *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__model_run_request__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__model_run_request__pack_to_buffer
                     (const Vaccel__Tf__ModelRunRequest *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__model_run_request__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__ModelRunRequest *
       vaccel__tf__model_run_request__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__ModelRunRequest *)
     protobuf_c_message_unpack (&vaccel__tf__model_run_request__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__model_run_request__free_unpacked
                     (Vaccel__Tf__ModelRunRequest *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__model_run_request__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
void   vaccel__tf__model_run_response__init
                     (Vaccel__Tf__ModelRunResponse         *message)
{
  static const Vaccel__Tf__ModelRunResponse init_value = VACCEL__TF__MODEL_RUN_RESPONSE__INIT;
  *message = init_value;
}
size_t vaccel__tf__model_run_response__get_packed_size
                     (const Vaccel__Tf__ModelRunResponse *message)
{
  assert(message->base.descriptor == &vaccel__tf__model_run_response__descriptor);
  return protobuf_c_message_get_packed_size ((const ProtobufCMessage*)(message));
}
size_t vaccel__tf__model_run_response__pack
                     (const Vaccel__Tf__ModelRunResponse *message,
                      uint8_t       *out)
{
  assert(message->base.descriptor == &vaccel__tf__model_run_response__descriptor);
  return protobuf_c_message_pack ((const ProtobufCMessage*)message, out);
}
size_t vaccel__tf__model_run_response__pack_to_buffer
                     (const Vaccel__Tf__ModelRunResponse *message,
                      ProtobufCBuffer *buffer)
{
  assert(message->base.descriptor == &vaccel__tf__model_run_response__descriptor);
  return protobuf_c_message_pack_to_buffer ((const ProtobufCMessage*)message, buffer);
}
Vaccel__Tf__ModelRunResponse *
       vaccel__tf__model_run_response__unpack
                     (ProtobufCAllocator  *allocator,
                      size_t               len,
                      const uint8_t       *data)
{
  return (Vaccel__Tf__ModelRunResponse *)
     protobuf_c_message_unpack (&vaccel__tf__model_run_response__descriptor,
                                allocator, len, data);
}
void   vaccel__tf__model_run_response__free_unpacked
                     (Vaccel__Tf__ModelRunResponse *message,
                      ProtobufCAllocator *allocator)
{
  if(!message)
    return;
  assert(message->base.descriptor == &vaccel__tf__model_run_response__descriptor);
  protobuf_c_message_free_unpacked ((ProtobufCMessage*)message, allocator);
}
static const ProtobufCFieldDescriptor vaccel__tf__tensor__field_descriptors[3] =
{
  {
    "data",
    1,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__Tensor, data),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "dims",
    2,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_INT64,
    offsetof(Vaccel__Tf__Tensor, n_dims),
    offsetof(Vaccel__Tf__Tensor, dims),
    NULL,
    NULL,
    0 | PROTOBUF_C_FIELD_FLAG_PACKED,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "type",
    3,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_ENUM,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__Tensor, type),
    &vaccel__tf__data_type__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__tensor__field_indices_by_name[] = {
  0,   /* field[0] = data */
  1,   /* field[1] = dims */
  2,   /* field[2] = type */
};
static const ProtobufCIntRange vaccel__tf__tensor__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 3 }
};
const ProtobufCMessageDescriptor vaccel__tf__tensor__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.Tensor",
  "Tensor",
  "Vaccel__Tf__Tensor",
  "vaccel.tf",
  sizeof(Vaccel__Tf__Tensor),
  3,
  vaccel__tf__tensor__field_descriptors,
  vaccel__tf__tensor__field_indices_by_name,
  1,  vaccel__tf__tensor__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__tensor__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor vaccel__tf__node__field_descriptors[2] =
{
  {
    "name",
    1,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_STRING,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__Node, name),
    NULL,
    &protobuf_c_empty_string,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "id",
    2,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_INT32,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__Node, id),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__node__field_indices_by_name[] = {
  1,   /* field[1] = id */
  0,   /* field[0] = name */
};
static const ProtobufCIntRange vaccel__tf__node__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor vaccel__tf__node__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.Node",
  "Node",
  "Vaccel__Tf__Node",
  "vaccel.tf",
  sizeof(Vaccel__Tf__Node),
  2,
  vaccel__tf__node__field_descriptors,
  vaccel__tf__node__field_indices_by_name,
  1,  vaccel__tf__node__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__node__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor vaccel__tf__model_load_request__field_descriptors[2] =
{
  {
    "session_id",
    1,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelLoadRequest, session_id),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "model_id",
    2,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelLoadRequest, model_id),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__model_load_request__field_indices_by_name[] = {
  1,   /* field[1] = model_id */
  0,   /* field[0] = session_id */
};
static const ProtobufCIntRange vaccel__tf__model_load_request__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor vaccel__tf__model_load_request__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.ModelLoadRequest",
  "ModelLoadRequest",
  "Vaccel__Tf__ModelLoadRequest",
  "vaccel.tf",
  sizeof(Vaccel__Tf__ModelLoadRequest),
  2,
  vaccel__tf__model_load_request__field_descriptors,
  vaccel__tf__model_load_request__field_indices_by_name,
  1,  vaccel__tf__model_load_request__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__model_load_request__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor vaccel__tf__model_load_response__field_descriptors[2] =
{
  {
    "graph_def",
    1,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelLoadResponse, graph_def),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "status",
    2,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelLoadResponse, status),
    &vaccel__status__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__model_load_response__field_indices_by_name[] = {
  0,   /* field[0] = graph_def */
  1,   /* field[1] = status */
};
static const ProtobufCIntRange vaccel__tf__model_load_response__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor vaccel__tf__model_load_response__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.ModelLoadResponse",
  "ModelLoadResponse",
  "Vaccel__Tf__ModelLoadResponse",
  "vaccel.tf",
  sizeof(Vaccel__Tf__ModelLoadResponse),
  2,
  vaccel__tf__model_load_response__field_descriptors,
  vaccel__tf__model_load_response__field_indices_by_name,
  1,  vaccel__tf__model_load_response__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__model_load_response__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor vaccel__tf__model_unload_request__field_descriptors[2] =
{
  {
    "session_id",
    1,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelUnloadRequest, session_id),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "model_id",
    2,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelUnloadRequest, model_id),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__model_unload_request__field_indices_by_name[] = {
  1,   /* field[1] = model_id */
  0,   /* field[0] = session_id */
};
static const ProtobufCIntRange vaccel__tf__model_unload_request__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor vaccel__tf__model_unload_request__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.ModelUnloadRequest",
  "ModelUnloadRequest",
  "Vaccel__Tf__ModelUnloadRequest",
  "vaccel.tf",
  sizeof(Vaccel__Tf__ModelUnloadRequest),
  2,
  vaccel__tf__model_unload_request__field_descriptors,
  vaccel__tf__model_unload_request__field_indices_by_name,
  1,  vaccel__tf__model_unload_request__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__model_unload_request__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor vaccel__tf__model_unload_response__field_descriptors[1] =
{
  {
    "status",
    1,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelUnloadResponse, status),
    &vaccel__status__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__model_unload_response__field_indices_by_name[] = {
  0,   /* field[0] = status */
};
static const ProtobufCIntRange vaccel__tf__model_unload_response__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 1 }
};
const ProtobufCMessageDescriptor vaccel__tf__model_unload_response__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.ModelUnloadResponse",
  "ModelUnloadResponse",
  "Vaccel__Tf__ModelUnloadResponse",
  "vaccel.tf",
  sizeof(Vaccel__Tf__ModelUnloadResponse),
  1,
  vaccel__tf__model_unload_response__field_descriptors,
  vaccel__tf__model_unload_response__field_indices_by_name,
  1,  vaccel__tf__model_unload_response__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__model_unload_response__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor vaccel__tf__model_run_request__field_descriptors[6] =
{
  {
    "session_id",
    1,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelRunRequest, session_id),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "model_id",
    2,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_INT64,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelRunRequest, model_id),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "run_options",
    3,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_BYTES,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelRunRequest, run_options),
    NULL,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "in_nodes",
    4,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    offsetof(Vaccel__Tf__ModelRunRequest, n_in_nodes),
    offsetof(Vaccel__Tf__ModelRunRequest, in_nodes),
    &vaccel__tf__node__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "out_nodes",
    5,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    offsetof(Vaccel__Tf__ModelRunRequest, n_out_nodes),
    offsetof(Vaccel__Tf__ModelRunRequest, out_nodes),
    &vaccel__tf__node__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "in_tensors",
    6,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    offsetof(Vaccel__Tf__ModelRunRequest, n_in_tensors),
    offsetof(Vaccel__Tf__ModelRunRequest, in_tensors),
    &vaccel__tf__tensor__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__model_run_request__field_indices_by_name[] = {
  3,   /* field[3] = in_nodes */
  5,   /* field[5] = in_tensors */
  1,   /* field[1] = model_id */
  4,   /* field[4] = out_nodes */
  2,   /* field[2] = run_options */
  0,   /* field[0] = session_id */
};
static const ProtobufCIntRange vaccel__tf__model_run_request__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 6 }
};
const ProtobufCMessageDescriptor vaccel__tf__model_run_request__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.ModelRunRequest",
  "ModelRunRequest",
  "Vaccel__Tf__ModelRunRequest",
  "vaccel.tf",
  sizeof(Vaccel__Tf__ModelRunRequest),
  6,
  vaccel__tf__model_run_request__field_descriptors,
  vaccel__tf__model_run_request__field_indices_by_name,
  1,  vaccel__tf__model_run_request__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__model_run_request__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCFieldDescriptor vaccel__tf__model_run_response__field_descriptors[2] =
{
  {
    "out_tensors",
    1,
    PROTOBUF_C_LABEL_REPEATED,
    PROTOBUF_C_TYPE_MESSAGE,
    offsetof(Vaccel__Tf__ModelRunResponse, n_out_tensors),
    offsetof(Vaccel__Tf__ModelRunResponse, out_tensors),
    &vaccel__tf__tensor__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
  {
    "status",
    2,
    PROTOBUF_C_LABEL_NONE,
    PROTOBUF_C_TYPE_MESSAGE,
    0,   /* quantifier_offset */
    offsetof(Vaccel__Tf__ModelRunResponse, status),
    &vaccel__status__descriptor,
    NULL,
    0,             /* flags */
    0,NULL,NULL    /* reserved1,reserved2, etc */
  },
};
static const unsigned vaccel__tf__model_run_response__field_indices_by_name[] = {
  0,   /* field[0] = out_tensors */
  1,   /* field[1] = status */
};
static const ProtobufCIntRange vaccel__tf__model_run_response__number_ranges[1 + 1] =
{
  { 1, 0 },
  { 0, 2 }
};
const ProtobufCMessageDescriptor vaccel__tf__model_run_response__descriptor =
{
  PROTOBUF_C__MESSAGE_DESCRIPTOR_MAGIC,
  "vaccel.tf.ModelRunResponse",
  "ModelRunResponse",
  "Vaccel__Tf__ModelRunResponse",
  "vaccel.tf",
  sizeof(Vaccel__Tf__ModelRunResponse),
  2,
  vaccel__tf__model_run_response__field_descriptors,
  vaccel__tf__model_run_response__field_indices_by_name,
  1,  vaccel__tf__model_run_response__number_ranges,
  (ProtobufCMessageInit) vaccel__tf__model_run_response__init,
  NULL,NULL,NULL    /* reserved[123] */
};
static const ProtobufCEnumValue vaccel__tf__data_type__enum_values_by_number[24] =
{
  { "UNUSED", "VACCEL__TF__DATA_TYPE__UNUSED", 0 },
  { "FLOAT", "VACCEL__TF__DATA_TYPE__FLOAT", 1 },
  { "DOUBLE", "VACCEL__TF__DATA_TYPE__DOUBLE", 2 },
  { "INT32", "VACCEL__TF__DATA_TYPE__INT32", 3 },
  { "UINT8", "VACCEL__TF__DATA_TYPE__UINT8", 4 },
  { "INT16", "VACCEL__TF__DATA_TYPE__INT16", 5 },
  { "INT8", "VACCEL__TF__DATA_TYPE__INT8", 6 },
  { "STRING", "VACCEL__TF__DATA_TYPE__STRING", 7 },
  { "COMPLEX", "VACCEL__TF__DATA_TYPE__COMPLEX", 8 },
  { "INT64", "VACCEL__TF__DATA_TYPE__INT64", 9 },
  { "BOOL", "VACCEL__TF__DATA_TYPE__BOOL", 10 },
  { "QINT8", "VACCEL__TF__DATA_TYPE__QINT8", 11 },
  { "QUINT8", "VACCEL__TF__DATA_TYPE__QUINT8", 12 },
  { "QINT32", "VACCEL__TF__DATA_TYPE__QINT32", 13 },
  { "BFLOAT16", "VACCEL__TF__DATA_TYPE__BFLOAT16", 14 },
  { "QINT16", "VACCEL__TF__DATA_TYPE__QINT16", 15 },
  { "QUINT16", "VACCEL__TF__DATA_TYPE__QUINT16", 16 },
  { "UINT16", "VACCEL__TF__DATA_TYPE__UINT16", 17 },
  { "COMPLEX128", "VACCEL__TF__DATA_TYPE__COMPLEX128", 18 },
  { "HALF", "VACCEL__TF__DATA_TYPE__HALF", 19 },
  { "RESOURCE", "VACCEL__TF__DATA_TYPE__RESOURCE", 20 },
  { "VARIANT", "VACCEL__TF__DATA_TYPE__VARIANT", 21 },
  { "UINT32", "VACCEL__TF__DATA_TYPE__UINT32", 22 },
  { "UINT64", "VACCEL__TF__DATA_TYPE__UINT64", 23 },
};
static const ProtobufCIntRange vaccel__tf__data_type__value_ranges[] = {
{0, 0},{0, 24}
};
static const ProtobufCEnumValueIndex vaccel__tf__data_type__enum_values_by_name[24] =
{
  { "BFLOAT16", 14 },
  { "BOOL", 10 },
  { "COMPLEX", 8 },
  { "COMPLEX128", 18 },
  { "DOUBLE", 2 },
  { "FLOAT", 1 },
  { "HALF", 19 },
  { "INT16", 5 },
  { "INT32", 3 },
  { "INT64", 9 },
  { "INT8", 6 },
  { "QINT16", 15 },
  { "QINT32", 13 },
  { "QINT8", 11 },
  { "QUINT16", 16 },
  { "QUINT8", 12 },
  { "RESOURCE", 20 },
  { "STRING", 7 },
  { "UINT16", 17 },
  { "UINT32", 22 },
  { "UINT64", 23 },
  { "UINT8", 4 },
  { "UNUSED", 0 },
  { "VARIANT", 21 },
};
const ProtobufCEnumDescriptor vaccel__tf__data_type__descriptor =
{
  PROTOBUF_C__ENUM_DESCRIPTOR_MAGIC,
  "vaccel.tf.DataType",
  "DataType",
  "Vaccel__Tf__DataType",
  "vaccel.tf",
  24,
  vaccel__tf__data_type__enum_values_by_number,
  24,
  vaccel__tf__data_type__enum_values_by_name,
  1,
  vaccel__tf__data_type__value_ranges,
  NULL,NULL,NULL,NULL   /* reserved[1234] */
};
